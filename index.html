<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zhengxiao Han</title>

    <meta name="author" content="Zhengxiao Han">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:1100px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zhengxiao Han
                  </p>
                  <p>I am a Master Student majoring in Robotics (<a href="https://www.mccormick.northwestern.edu/robotics/">MSR Program</a>) at Northwestern Univeristy. 
                    I received my Bachelor's degree in 2023 at <a href="https://english.buct.edu.cn/main.htm">Beijing University of Chemical Technology</a>.
                  </p>
                  <p>
                    I spent one year as a Research Assistant at 
                    <a href="https://zsdonghao.github.io/">PKU-Agibot (智元机器人) Lab</a>, Peking University, 
                    advised by Prof. <a href="https://zsdonghao.github.io/"> Hao Dong</a>.
                  </p>
                  <p>
                    I spent two years as a Research Intern at <a href="https://air.tsinghua.edu.cn/en/">DISCOVER Lab</a> at Tsinghua University, 
                    advised by <a href="https://x.com/arx_zhang?lang=en">Xinliang Zhang</a>, Prof. <a href="https://sites.google.com/view/fromandto">Hao Zhao</a> and 
                    Prof. <a href="https://www.innovatorsunder35.com/the-list/guyue-zhou/">Guyue Zhou</a>. During this time, I collaborated closely with 
                    <a href="https://arx-x.com/">ARX (方舟无限)</a> and <a href="https://airbots.online/">DISCOVER Robotics (求之科技)</a> during their formative stages, 
                    prior to their official founding.
                  </p>
                  <p>
                    Proudly, I am a founding contributor to 
                    <a href="https://www.kickstarter.com/projects/336477435/mini-pupper-open-sourceros-robot-dog-kit"> Mini Pupper</a>, 
                    an open-source quadruped robot, when I was a junior.
                  </p>
                  <p>
                    I am <b style="color: #FF0000;">actively</b> seeking PhD positions in Robotics for 2025 Fall, 2026 Spring and 2026 Fall.
                  </p>
                  <p style="text-align:center">
                    <a href="https://www.linkedin.com/in/purimagination/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/0nhc/">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://x.com/serious0nhc">X</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=m0KhpYUAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="mailto:hanzx@u.northwestern.edu">Email</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="index.html">
                    <img 
                    style="width:70%;max-width:100%;object-fit: cover; border-radius: 50%;" 
                    alt="profile photo" 
                    src="images/favicon/android-chrome-512x512.png" 
                    class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

        <!-- News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 class="news-heading">🔥 News</h2>
                <ul id="newsList">
                  <li>
                    <p><span class="news-date">[2025.01]</span> 🎉 One paper gets accepted to ICRA 2025.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2024.09]</span> 🎓 I started <a href="https://www.mccormick.northwestern.edu/robotics/">Master in Robotics (MSR)</a> program at Northwestern University.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2023.09]</span> 💼 I started my gap year as a research assistant at <a href="https://zsdonghao.github.io/">PKU-Agibot (智元机器人) Lab</a>, Peking University.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2023.07]</span> 🎉 Two papers get accepted to CICAI 2023, with a <b>Best Demo Award.</b></p>
                  </li>
                  <li>
                    <p><span class="news-date">[2023.07]</span> 🎉 One paper gets accepted to ICCV 2023.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2023.06]</span> 🎓 Get my B.Eng. in Mechanical Engineering at Beijing Univeristy of Chemical Technology.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2022.10]</span> 🦾 Improved <a href="https://www.kickstarter.com/projects/mdrobotkits/mini-pupper-2-open-source-ros2-robot-kit-for-dreamers">Mini Pupper 2</a> and launched it on Kickstarter.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2022.06]</span> 🎉 Published an <a href="https://aws.amazon.com/blogs/robotics/build-and-simulate-a-mini-pupper-robot-in-the-cloud-without-managing-any-infrastructure/">AWS Robotics Blog</a> in deploying applcation changes from cluod-based simulation to real robot hardware.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2022.05]</span> 🏆 We get a <a href="https://github.com/mvyp/.github/blob/main/profile/imgs/2.jpg">Third Prize</a> in ICRA 2022 RoboMaster University Sim2Real Challenge.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2021.10]</span> 💼 I started my roboitcs journey as an intern at <a href="https://air.tsinghua.edu.cn/en/index.htm">Institute for Al Industry Research (AIR)</a>, Tsinghua University.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2021.09]</span> 🦾 Our open-source quadruped robot <a href="https://www.kickstarter.com/projects/mdrobotkits/mini-pupper-open-sourceros-robot-dog-kit/description">Mini Pupper</a> is launched on Kickstarter, and crowd-funded about $500, 000.</p>
                  </li>
                  <li>
                    <p><span class="news-date">[2021.05]</span> 🏆 We get a <a href="https://github.com/mvyp/.github/blob/main/profile/imgs/4.jpg">Second Prize</a> in RoboCup@Home 2021, China.</p>
                  </li>
                </ul>
                <a href="#" id="expandNews" class="expand-link">Show more</a>
              </td>
            </tr>
          </tbody>
        </table>
        <script>
          const newsList = document.getElementById('newsList');
          const expandLink = document.getElementById('expandNews');
          const newsItems = newsList.getElementsByTagName('li');
          const initialDisplay = 5;
          let isExpanded = false;
          function toggleNews() {
            for (let i = initialDisplay; i < newsItems.length; i++) {
              newsItems[i].classList.toggle('hidden');
            }
            isExpanded = !isExpanded;
            expandLink.textContent = isExpanded ? 'Show less' : 'Show more';
          }
          if (newsItems.length > initialDisplay) {
            for (let i = initialDisplay; i < newsItems.length; i++) {
              newsItems[i].classList.add('hidden');
            }
            expandLink.style.display = 'inline-block';
          } else {
            expandLink.style.display = 'none';
          }
          expandLink.addEventListener('click', function(e) {
            e.preventDefault();
            toggleNews();
          });
        </script>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <h2>🧑‍🎓 Education</h2>
              </td>
            </tr>
            <tr>
              <td width="75%" valign="center">
                <b>Northwestern University, Evanston, Illinois, U.S.A.</b></br>
                Master of Science, Robotics</br>
                <em style="color:grey;">2024-2025</em></br>
                GPA: 4.00/4.00
              </td>
            </tr>
            <tr>
              <td width="75%" valign="center">
                <b>Beijing University of Chemical Technology, Beijing, China</b></br>
                Bachelor of Engineering, Mechanical Design, Manufacturing and Its Automation</br>
                <em style="color:grey;">2019-2023</em></br>
                GPA: 87.4/100, Ranking: 6/72. Ex-president of <a href="https://github.com/mvyp/"> SIE Robotics Club</a>. Guitar player in the Towers (a student band).
              </td>
            </tr>
          </tbody>
        </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>📚 Publications</h2>
                  <p>
                    * : Equal contribution; †: Corresponding author(s)
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="cicai()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='cicai' style="opacity: 0;">
                    </div>
                    <img src='images/RL2.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('m2sim').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('m2sim').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Enhancing Daily Life Through an Interactive Desktop Robotics System</span>
                  <br>
                  <a href="https://mrsecant.github.io/">Yuhang Zheng</a>, 
                  <a href="https://king-bridge.github.io/">Qiyao Wang</a>, 
                  <a href="https://zhongcl-thu.github.io/">Chengliang Zhong<sup>&dagger;</sup></a>, 
                  <a href="index.html">He Liang</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="index.html">Yupeng Zheng</a>
                  </br>
                  <strong>
                  <em>CICAI, 2023</em>
                  🏆
                  <em style="color: #FF0000;">Best Demo Award</em>
                  </strong>
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007/978-981-99-9119-8_8">
                    <b>
                      [Paper]
                    </b>
                  </a>
                  <a href="https://www.bilibili.com/video/BV1UX4y1n7DJ">
                    <b>
                      [Video]
                    </b>
                  </a>
                  <p>
                    We developed an intelligent desktop operating robot designed to assist 
                    humans in their daily lives by comprehending natural language with large 
                    language models and performing a variety of desktop-related tasks.
                  </p>
                </td>
              </tr>

              <tr onmouseout="m2sim()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='m2sim' style="opacity: 0;">
                    </div>
                    <img src='images/m2sim.jpg' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('m2sim').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('m2sim').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Long-term Interactive Driving Simulation: MPC to the Rescue</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://scholar.google.com/citations?user=4PXGeaYAAAAJ">Zhijie Yan</a>, 
                  <a href="https://www.linkedin.com/in/yang-li-2000/">Yang Li</a>, 
                  <a href="https://philipflyg.github.io/">Pengfei Li</a>, 
                  <a href="https://scholar.google.com/citations?user=KlHuj2QAAAAJ">Yifeng Shi</a>, 
                  <a href="index.html">Nairui Luo</a>, 
                  <a href="https://scholar.google.com/citations?user=qCbWxzgAAAAJ">Xu Gao</a>, 
                  <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ">Yongliang Shi</a>, 
                  <a href="index.html">Pengfei Huang</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>, 
                  <a href="https://hangzhaomit.github.io/">Hang Zhao</a>, 
                  <a href="https://sites.google.com/view/fromandto">Hao Zhao<sup>&dagger;</sup></a>
                  </br>
                  <strong>
                    <em>CICAI, 2023</em>
                  </strong>
                  <br>
                  <a href="data/CICAI_Paper_Camera_Ready.pdf">
                    <b>
                      [Paper]
                    </b>
                  </a>
                  <a href="https://github.com/0nhc/m2sim">
                    <b>
                      [Code]
                    </b>
                  </a>
                  <a href="https://www.youtube.com/watch?v=Xdxto_ivJ_4">
                    <b>
                      [Video]
                    </b>
                  </a>
                  <p>
                    Cooperated with Baidu Apollo and MARS Lab at Tsinghua University. We propose to introduce a tailored Model Predictive Control 
                    (MPC) module as a rescue into the state-of-the art 
                    interactive trajectory prediction model M2I. Notably, our method can effectively address the Out-of-Domain (OOD) 
                    problem in long-term simulation by enforcing a flexible regularization that admits the replayed data, while still 
                    enjoying the diversity of data-driven predictions.
                  </p>
                </td>
              </tr>

              <tr onmouseout="int2()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='int2' style="opacity: 0;">
                    </div>
                    <img src='images/int2.jpg' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('int2').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('int2').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">INT2: Interactive Trajectory Prediction at Intersections</span>
                  <br>
                  <a href="https://scholar.google.com/citations?user=4PXGeaYAAAAJ">Zhijie Yan</a>, 
                  <a href="https://philipflyg.github.io/">Pengfei Li</a>, 
                  <a href="https://scholar.google.com/citations?user=wDMrCnIAAAAJ">Zheng Fu</a>, 
                  <a href="https://daniellli.github.io/">Shaocong Xu</a>, 
                  <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ">Yongliang Shi</a>, 
                  <a href="https://scholar.google.com/citations?user=_tz64W0AAAAJ">Xiaoxue Chen</a>, 
                  <a href="https://mrsecant.github.io/">Yuhang Zheng</a>, 
                  <a href="https://www.linkedin.com/in/yang-li-2000/">Yang Li</a>, 
                  <a href="index.html">Tianyu Liu</a>, 
                  <a href="https://www.linkedin.com/in/lichuxuan/">Chuxuan Li</a>, 
                  <a href="index.html">Nairui Luo</a>, 
                  <a href="https://scholar.google.com/citations?user=qCbWxzgAAAAJ">Xu Gao</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>, 
                  <a href="index.html">Zuoxu Wang</a>, 
                  <a href="https://scholar.google.com/citations?user=KlHuj2QAAAAJ">Yifeng Shi</a>, 
                  <a href="index.html">Pengfei Huang</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1012/1219.htm">Jirui Yuan</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>, 
                  <a href="https://hangzhaomit.github.io/">Hang Zhao</a>, 
                  <a href="https://sites.google.com/view/fromandto">Hao Zhao<sup>&dagger;</sup></a>
                  </br>
                  <strong>
                    <em>ICCV, 2023</em>
                  </strong>
                  <br>
                  <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.pdf">
                    <b>
                      [Paper]
                    </b>
                  </a>
                  <a href="https://github.com/AIR-DISCOVER/INT2">
                    <b>
                      [Code]
                    </b>
                  </a>
                  <a href="https://www.youtube.com/watch?v=KNkuakDvgVc">
                    <b>
                      [Video]
                    </b>
                  </a>
                  <p>
                    We present a large-scale interactive trajectory prediction dataset named INT2 for INTeractive 
                    trajectory prediction at INTersections. INT2 includes 612,000 scenes, each lasting 1 minute, 
                    containing up to 10,200 hours of data. We benchmark the best open-sourced interactive trajectory 
                    prediction method on INT2 and Waymo Open Dataset, under in-domain and cross-domain settings.
                  </p>
                </td>
              </tr>

              <tr onmouseout="aws_blog_mini_pupper()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='aws_blog_mini_pupper' style="opacity: 0;">
                    </div>
                    <img src='images/aws_blog_mini_pupper.jpg' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('aws_blog_mini_pupper').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('aws_blog_mini_pupper').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Build and simulate a Mini Pupper robot in the cloud without managing any infrastructure</span>
                  <br>
                  <a href="https://www.linkedin.com/in/bingjiao-yu?originalSubdomain=cn">Bingjiao Yu</a>, 
                  <a href="https://www.linkedin.com/in/afreez-gan-b606615/?originalSubdomain=hk">Afreez Gan</a>, 
                  <a href="https://www.linkedin.com/in/hansenmattk/">Matt Hansen</a>, 
                  <a href="https://www.linkedin.com/in/xiao-yang-zhu-69967414/?originalSubdomain=cn">Xiaoyang Zhu</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>
                  </br>
                  <strong>
                  <em>AWS Robotics Blog, 2022</em>
                  </strong>
                  <br>
                  <a href="https://aws.amazon.com/blogs/robotics/build-and-simulate-a-mini-pupper-robot-in-the-cloud-without-managing-any-infrastructure/">
                    <b>
                      [Blog]
                    </b>
                  </a>
                  </a>
                  <p>  
                    In this blog, we highlight how AWS RoboMaker simplifies robotics simulation. Using the Mini Pupper robot, 
                    we demonstrate how developers can build and test ROS-based navigation applications in a managed cloud environment. 
                    AWS Cloud9 streamlines development, while AWS RoboMaker enables scalable, parallel testing. This cloud-based solution makes 
                    robotics development more accessible, accelerating workflows and reducing infrastructure management.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>🦾 Projects</h2>
                  <p>
                    I have always been working on Robotics.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="rds2025_2n()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='rds2025_2n' style="opacity: 0;">
                    </div>
                    <img src='images/robocup.mp4' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('rds2025_2n').style.opacity = "1";
                    }
    
                    function bog_stop() {
                      document.getElementById('rds2025_2n').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Tendon-Driven Dexterous Hand Basics: 2N Finger</span>
                  <br>
                  <a href="https://www.linkedin.com/in/klaudon/">Konrad Laudon</a>, 
                  <a href="https://www.linkedin.com/in/eliana-storkamp-7771ab22a/">Eliana Storkamp</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://www.linkedin.com/in/cwseif/">Charlie Seifert</a>, 
                  <a href="https://www.linkedin.com/in/sairam-umakanth/">Sairam Umakanth</a>, 
                  <a href="https://www.linkedin.com/in/yifei-chen-a89498310/">Yifei Chen</a>,
                  <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/lynch-kevin.html">Kevin Lynch</a>
                  </br>
                  <strong>
                    <em>Warm-up Project for <a href="https://www.mccormick.northwestern.edu/mechanical/academics/courses/descriptions/472-1-robot-design-studio.html">ME472: Robot Design Studio</a></em>
                  </strong>
                  <br>
                  <a href="https://github.com/NU-RDS/2n-codebase">
                    <b>
                      [Code]
                    </b>
                  </a>
                  <a href="https://absrat.com/rds2025_team2n">
                    <b>
                      [Documentation]
                    </b>
                  </a>
                  <p>
                    This warm-up project for Robot Design Studio explores the concept of a dexterous 2N finger. 
                    Built with a 3D-printed structure, tendon-driven actuation, and ODrive Pro-controlled brushless motors, 
                    it uses custom CAN and serial protocols for smooth communication between the Teensy, ODrive, and laptop. 
                    We verified the kinematics by displaying joint states in the GUI and Rviz, integrated a ROS 2 interface 
                    for future expansion, and demonstrated PD control.
                    One more thing, we over-toasted one ODrive Pro (1*$229), two Teensy 4.1 boards(2*$31.5), and four MCP2561 chips(4*$1.28)!
                  </p>
                </td>
              </tr>

              <tr onmouseout="pcd_classify()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='pcd_classify' style="opacity: 0;">
                    </div>
                    <img src='images/pcd_classify.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('pcd_classify').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('pcd_classify').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
              <td style="padding:35px;width:75%;vertical-align:middle">
                <span class="papertitle">Point Cloud Classification</span>
                <br>
                <a href="index.html"><b>Zhengxiao Han</b></a>, 
                <a href="https://wengmister.github.io/">Zhengyang (Kris) Weng</a>,
                <a href="https://benbenyamin.github.io/">Ben Benyamin</a>,
                <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/demeter-david.html">David Demeter</a>
                </br>
                <strong>
                  <em>Final Project for <a href="https://www.mccormick.northwestern.edu/artificial-intelligence/curriculum/descriptions/msai-349.html">MSAI349: Machine Learning</a></em>
                </strong>
                <br>
                <a href="https://github.com/msr-in-msai/msai-349-final-project">
                  <b>
                    [Code]
                  </b>
                </a>
                <p>
                  We developed a PyTorch object classification model that processes point cloud data enriched with RGB 
                  information using a modified PointNet architecture. Our approach leverages a realistic dataset generated 
                  in Isaac Sim from <a href="https://omniobject3d.github.io/">OmniObject3d</a> object models, capturing RGB-D 
                  images and segmentation labels for five classes 
                  (apple, banana, bottle, bowl, cup). With a four-layer MLP, max pooling, and transformation networks 
                  addressing order and pose variations, our model achieves 70% testing accuracy and outperforms traditional KNN methods.
                </p>
              </td>
            </tr>


              <tr onmouseout="doodle_droid()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='doodle_droid' style="opacity: 0;">
                    </div>
                    <img src='images/doodle_droid.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('doodle_droid').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('doodle_droid').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Doodle Droid <b style="color: #FF0000;">(Reposted by Franka Robotics)</b></span>
                  <br>
                  <a href="https://ykechriotis.github.io/">Yanni Kechriotis</a>, 
                  <a href="https://cappuccinopanda.github.io/website/">David Matthews</a>, 
                  <a href="https://github.com/HarrisonBounds">Harrison Bounds</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="index.html">Christian Tongate</a>, 
                  <a href="https://robotics.northwestern.edu/people/profiles/faculty/elwin-matt.html">Matthew Elwin</a>
                  </br>
                  <strong>
                    <em>Final Project for <a href="https://nu-msr.github.io/ros_notes/index.html">ME495: Embedded Systems in Robotics</a></em>
                  </strong>
                  <br>
                  <a href="https://github.com/HarrisonBounds/DoodleDroid">
                    <b>
                      [Code]
                    </b>
                  </a>
                  <a href="https://www.linkedin.com/posts/harrison-bounds_introducing-doodle-droid-a-portrait-drawing-activity-7293646260731883520-NiNA?utm_source=share&utm_medium=member_desktop&rcm=ACoAADc8j2YBWU41NvujlwJ5927HA9-7dKcrazM">
                    <b>
                      [LinkedIn Post]
                    </b>
                  </a>
                  <p>
                    A franka robot arm is used to draw portraits as line art. 
                    Users can take a photo of themselves or others which the robot will convert to pen strokes and draw 
                    them on a paper detected and localized using april tags. My primary role is to develop the MoveIt 2 API library. 
                    My secondary role is to integrate the code.
                  </p>
                </td>
              </tr>

              <tr onmouseout="msr_hackathon()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='msr_hackathon' style="opacity: 0;">
                    </div>
                    <img src='images/msr_hackathon.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('msr_hackathon').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('msr_hackathon').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Northwestern University MSR Hackathon</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://robotics.northwestern.edu/people/profiles/faculty/elwin-matt.html">Matthew Elwin</a>
                  <p>
                    My MSR journey at Northwestern University kicked off with an intense two-week hackathon. We firstly reviewed BFS, DFS and RRT path planning algorithms. 

                    The most complex challenge was designing a robotic grasping system. I used HSV filtering to create a mask for detecting a purple pen, and by leveraging the camera's intrinsic matrix and aligned depth image, I calculated the pen's 3D position. To handle camera movements, I used an ArUco tag to dynamically calculate the transformation between the camera and robotic arm, making my system robust to any accidental camera shifts. At last I can generate a 6D grasping pose for the robotic arm.
                  </p>
                </td>
              </tr>

              <tr onmouseout="active_perception()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='active_perception' style="opacity: 0;">
                    </div>
                    <img src='images/active_perception.jpg' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('active_perception').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('active_perception').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Synthetic Grasping Dataset Generation</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>
                  <p>
                    I generated a synthetic dataset by Utilizing Isaac Sim and <a href="https://omniobject3d.github.io/">OmniObject3d</a>. 
                    By extracting the model's pointcloud, I used RANSAC to fit the planes, then calculate the normal vectors, and finally 
                    used convex hulls to find areas that can place other objects. With this pipeline, I generated more than 300,000 data 
                    samples including RGB, Depth, and Segmentation information for training a grasping policy. The whole data generation 
                    process was done by me independently.
                  </p>
                </td>
              </tr>

              <tr onmouseout="dex_7dof()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dex_7dof' style="opacity: 0;">
                    </div>
                    <img src='images/dex_7dof.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('dex_7dof').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('dex_7dof').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">7-DOF Humanoid Robotic Arm with Tactile-enabled Dexterous Hand</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://kingchou007.github.io">Jinzhou Li</a>, 
                  <a href="https://ceca.pku.edu.cn/en/people_/faculty_/tao_wang/">Tao Wang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>
                  <p>
                  Constructed a 7-DOF humanoid robotic arm with dexterous hands equipped with tactile sensors for data collection, 
                  and interfaced it with ROS Control and MoveIt. All work was done by me independently.
                  We will work on encoding visual, tactile (not vision-based) and joint signals for imitation learning and deploy learned policies on real robots.
                  </p>
                </td>
              </tr>


              <tr onmouseout="tactile_sensor()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tactile_sensor' style="opacity: 0;">
                    </div>
                    <img src='images/bi_9dtact.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('tactile_sensor').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('tactile_sensor').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Vision-based Tactile Sensor</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>
                  <p>
                    Developed a binocular version of <a href="https://linchangyi1.github.io/9DTact/">9DTact</a>, 
                    a vision-based tactile sensor for robotic grasping. I independently designed all mechanical 
                    and electrical components—including the 3D-printed housing and custom PCB. Although the design 
                    showed promise, camera lens issues eventually rendered this version obsolete.
                  </p>
                </td>
              </tr>

              <tr onmouseout="full_stack_6dof()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='full_stack_6dof' style="opacity: 0;">
                    </div>
                    <img src='images/full_stack_6dof.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('full_stack_6dof').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('full_stack_6dof').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Full-stack 6-DOF robotic arm development</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>	
                  <p>
                  Achived hardware design of a new 6-DOF robotic arm, 
                  and interfaced all hardware under ROS Control and MoveIt. Interfaced the robotic arm with 
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Graspness_Discovery_in_Clutters_for_Fast_and_Accurate_Grasp_Detection_ICCV_2021_paper.pdf">GSNet</a> and achived a grasping demo. All work was done by me independently.
                  </p>
                </td>
              </tr>

              <tr onmouseout="full_stack_arm_and_gripper()" onmouseover="bog_start()"></tr>
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='full_stack_arm_and_gripper' style="opacity: 0;">
                    </div>
                    <img src='images/full_stack_arm_and_gripper.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('full_stack_arm_and_gripper').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('full_stack_arm_and_gripper').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle">Full-stack 6-DOF robotic arm and gripper development</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>	
                  <p>
                  Achived hardware design of a 6-DOF robotic arm and a 2-finger adaptive parallel gripper 
                  (same capability as <a href="https://robotiq.com/products/2f85-140-adaptive-robot-gripper">Robotiq 2f-85 Gripper</a>).
                  Constructed a robotic arm SDK with CMake, and interfaced the lib with ROS and Isaac Sim.
                  </p>
                </td>
              </tr>

              <tr onmouseout="bimanual_demonstration()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bimanual_demonstration' style="opacity: 0;">
                    </div>
                    <img src='images/bimanual_demonstration.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('bimanual_demonstration').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('bimanual_demonstration').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.bilibili.com/video/BV1iN411t7eb">Bimanual Demonstration System</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://github.com/ShanningZhuang">Shanning Zhuang</a>, 
                  <a href="http://robotics-tongji.org/members/zihangchen">Zihang Chen</a>, 
                  <a href="https://github.com/GDDG08">Zihan Zhuang</a>, 
                  <a href="http://www.iden.cn/home/active.NewYouzhan/workinfo?sc=yx&id=13012">Ximing Wang</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>
                  <p>
                  Inspired by ALOHA, we proposed an improved bimanual demonstration system. 
                  Constructed the SDK using C++ and CMake. Utilized KDL to solve kinematic and dynamic problems, 
                  then achived gravity compensation based on inverse dynamics. 
                  Designed a parallel two-finger gripper based on rack-gear structures. 
                  </p>
                </td>
              </tr>

              <tr onmouseout="mini_pupper_2()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mini_pupper_2' style="opacity: 0;">
                    </div>
                    <img src='images/mini_pupper_2.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('mini_pupper_2').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('mini_pupper_2').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.kickstarter.com/projects/336477435/mini-pupper-2-open-source-ros2-robot-kit-for-dreamers">Mini Pupper 2: Open-Source Quadruped Robot Dog Kit</a></span>
                  <br>
                  <a href="www.linkedin.com/in/afreez-gan-b606615">Afreez Gan</a>, 
                  <a href="index.html">Lily Wang</a>, 
                  <a href="index.html">Jian Song</a>, 
                  <a href="https://www.linkedin.com/in/marcin-pryli%C5%84ski-a79190249/">Marcin Prylinski</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://github.com/Ericsii">Yunlong Feng</a>
                  <p>
                    Developed all the ROS 2 (Humble) software suite including Locomotion, SLAM, Navigation, and CV functions. 
                    Deployed Cartographer with an Extended Kalman Filter (EKF) to fuse IMU data and LiDAR odometry, 
                    enhancing the robostness and accuracy of Mini Pupper's localization system.
                  </p>
                </td>
              </tr>

              <tr onmouseout="multi_robot()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='multi_robot' style="opacity: 0;">
                    </div>
                    <img src='images/multi_robot.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('multi_robot').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('multi_robot').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.youtube.com/watch?v=kmLZ6OmiqrY">Cooperative Multi-Robot System</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="index.html">Jingtian Deng</a>, 
                  <a href="https://linden713.github.io/">Chenghao Lin</a>, 
                  <a href="https://changerc77.github.io/">Xiangyu Chen</a>, 
                  <a href="https://www.linkedin.com/in/tian-ao-ren-2a0349220/">Tianao Ren</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>
                  <p>
                    Utilized Pure Pursuit algorithm for multi-robot formation control, which was tested in both real world and Isaac Sim. 
                    Utilized an EKF-based 2D LiDAR localization system as the odometry. 
                    Utilized KDL for solving kinematic problems of our own 6-DOF robotic arm, 
                    and combined it with the odometry, achieving Chiken-Head Mode. 
                    Combined all the functions above, and constructed a multi-robot cooperative system to carry a box in Isaac Sim.
                  </p>
                </td>
              </tr>

              <tr onmouseout="rmus()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='rmus' style="opacity: 0;">
                    </div>
                    <img src='images/rmus.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('rmus').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('rmus').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://youtu.be/7V5SHpF0PHM">ICRA 2022 RoboMaster University Sim2real Challenge</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://linden713.github.io/">Chenghao Lin</a>, 
                  <a href="https://www.linkedin.com/in/tian-ao-ren-2a0349220/">Tianao Ren</a>, 
                  <a href="index.html">Luoji Zhu</a>, 
                  <a href="index.html">Haitao Rao</a>
                  <p>
                    Deployed an Extended Kalman Filter (EKF) alongside an omnidirectional motion model for state estimation using sensor data, including IMU and odometry.
                    Utilized A* algorithm for global path planning and Timed Elastic Band (TEB) algorithm for local path planning. 
                    Utilized ArUco library for detecting boxes' poses.
                  </p>
                </td>
              </tr>

              <tr onmouseout="mini_pupper()" onmouseover="bog_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mini_pupper' style="opacity: 0;">
                    </div>
                    <img src='images/mini_pupper.gif' width=200%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('mini_pupper').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('mini_pupper').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:35px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.kickstarter.com/projects/336477435/mini-pupper-open-sourceros-robot-dog-kit">Mini Pupper: Open-Source Quadruped Robot Dog Kit</a></span>
                  <br>
                  <a href="www.linkedin.com/in/afreez-gan-b606615">Afreez Gan</a>, 
                  <a href="https://www.linkedin.com/in/marcin-pryli%C5%84ski-a79190249/">Marcin Prylinski</a>, 
                  <a href="https://twitter.com/tomato5356">Xiongshi Xu</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>
                  <p>
                    Inspired by Stanford's open-source quadruped robot <a href="https://pupper.readthedocs.io/en/latest/">Pupper</a>, I designed my own mechanical hardware, mainly improved its leg structures. 
                    After that, I was contacted by Mini Pupper's team and joined them. We developed the first product together. 
                    I independently developed all the ROS software suite including Locomotion, SLAM, Navigation, and CV functions. 
                    We crowd-funded $500,000 on Kickstarter when I was a junior.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Miscellaneous</h2>
                  <p>
                    <li>
                    <a href="https://hackaday.com/2021/09/27/robot-dogs-hack-chat/">Hackday Chat</a> on quadruped robots.
                    </li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:50%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px;text-align:right;font-size:small">
                  <br>
                  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=p9qCYK-rJEcF_FBhZsQbjU7RvhXNquQf7q7s7NNyOiA&cl=ffffff&w=a"></script>
                  <p style="text-align:center;font-size:small;">
                    Design and source code from <a href="https://github.com/jonbarron/website">Jon Barron's website</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </table>
  </body>
</html>
